#!/usr/bin/env python3

from cv_bridge import CvBridge
import pyrealsense2 as rs
import signal, time, numpy as np
import sys, cv2, rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import String
import numpy as np


isOk= True
def signalInteruption(signum, frame):
    global isOk
    print( "\nCtrl-c pressed" )
    isOk= False

# Node processes:
def process_img(args=None):
    global isOk, color, rayon_detec
    rclpy.init(args=args)
    rsNode= Realsense()
    
    rsNode.declare_parameter('color', 55)
    color = rsNode.get_parameter('color').value
    
    rsNode.declare_parameter('rayon_detec', 10)
    rayon_detec = rsNode.get_parameter('rayon_detec').value

    while isOk:
        # rsNode.read_imgs()
        rsNode.analyse_imgs()
        rclpy.spin_once(rsNode, timeout_sec=0.1)


    # Stop streaming
    print("Ending...")
    rsNode.pipeline.stop()
    # Clean end
    rsNode.destroy_node()
    rclpy.shutdown()

# Realsense Node:
class Realsense(Node):
    def __init__(self, fps= 60):
        super().__init__('object_detection')
        self.image_publisher = self.create_publisher(Image, '/sensor_image', 10)
        self.detec_publisher = self.create_publisher(String, '/detection_objet', 10)
        self.depth_publisher = self.create_publisher(Image, '/sensor_depth', 10)
        self.pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 848, 480, rs.format.bgr8, 60)
        config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 60)
        self.pipeline.start(config)

    def analyse_imgs(self):
        global color, rayon_detec
        self.frames = self.pipeline.wait_for_frames()
        color_frame = self.frames.first(rs.stream.color)
        color_image = np.asanyarray(color_frame.get_data())

        self.bridge=CvBridge()

        lo=np.array([color-5, 100, 50])
        hi=np.array([color+5, 255,255])
        kernel = np.ones((7, 7), np.uint8)
        color_info=(0, 0, 255)

        print("color image")
        print(color_image)
        image=cv2.cvtColor(color_image, cv2.COLOR_BGR2HSV)

        print("image")
        print(image)
        mask=cv2.inRange(image, lo, hi)
        mask=cv2.erode(mask, kernel, iterations=1)
        mask=cv2.dilate(mask, kernel, iterations=1)
        image2=cv2.bitwise_and(color_image, color_image, mask= mask)

        elements=cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]
        if len(elements) > 0:
            c=max(elements, key=cv2.contourArea)
            ((x, y), rayon)=cv2.minEnclosingCircle(c)
            if rayon>rayon_detec:
                cv2.circle(image2, (int(x), int(y)), int(rayon), color_info, 2)
                cv2.circle(color_image, (int(x), int(y)), 5, color_info, 10)
                cv2.line(color_image, (int(x), int(y)), (int(x)+150, int(y)), color_info, 2)
                cv2.putText(color_image, "Objet !!!", (int(x)+10, int(y) -10), cv2.FONT_HERSHEY_DUPLEX, 1, color_info, 1, cv2.LINE_AA)
                msg = String()
                msg.data = "trouve"
                self.detec_publisher.publish(msg)

        msg_image = self.bridge.cv2_to_imgmsg(color_image,"bgr8")
        msg_image.header.stamp = self.get_clock().now().to_msg()
        msg_image.header.frame_id = "image"
        self.image_publisher.publish(msg_image)

        depth_frame = self.frames.first(rs.stream.depth)
        depth_image = np.asanyarray(depth_frame.get_data())
        
        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)

        msg_depth = self.bridge.cv2_to_imgmsg(depth_colormap,"bgr8")
        msg_depth.header.stamp = msg_image.header.stamp
        msg_depth.header.frame_id = "depth"
        self.depth_publisher.publish(msg_depth)

process_img()