#!/usr/bin/env python3

from cv_bridge import CvBridge
import pyrealsense2 as rs
import signal, time, numpy as np
import sys, cv2, rclpy, math
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import String
from kobuki_ros_interfaces.msg import Sound
from geometry_msgs.msg import Vector3
from matplotlib import pyplot as plt
from interfaces_robot.msg import ImageCoord, StringVect


isOk= True
def signalInteruption(signum, frame):
    global isOk
    print( "\nCtrl-c pressed" )
    isOk= False

# Node processes:
def process_img(args=None):
    global isOk, color, rayon_detec
    rclpy.init(args=args)
    rsNode= Realsense()
    
    #Déclaration des paramètres rentrés via le launch file
    rsNode.declare_parameter('color', 75)
    color = rsNode.get_parameter('color').value

    rsNode.declare_parameter('rayon_detec', 40)
    rayon_detec = rsNode.get_parameter('rayon_detec').value

    while isOk:
        # rsNode.read_imgs()
        rsNode.analyse_imgs()
        rclpy.spin_once(rsNode, timeout_sec=0.1)


    # Stop streaming
    print("Ending...")
    rsNode.pipeline.stop()
    # Clean end
    rsNode.destroy_node()
    rclpy.shutdown()

# Realsense Node:
class Realsense(Node):
    def __init__(self, fps= 60):
        super().__init__('object_detection')
        self.image_publisher = self.create_publisher(Image, '/sensor_image', 10)        #Publisher image en couleur
        self.detec_publisher = self.create_publisher(String, '/detection_objet', 10)    #Publisher de détection de fantome
        self.depth_publisher = self.create_publisher(Image, '/sensor_depth', 10)        #Publisher image de distance
        self.imagecoord_publisher = self.create_publisher(ImageCoord, '/ImageDepthCoord', 10)   #publisher image pour analyse template matching
        self.sound_publisher = self.create_publisher(Sound, '/commands/sound', 10)      #Publisher de son
        self.goal_publisher = self.create_publisher(StringVect, '/position_objet', 10)           #Publisher position du fantome
        self.matching_listener = self.create_subscription(StringVect, '/fantome', self.fantome_callback, 10)

        #ouverture du flux via la caméra
        self.pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 848, 480, rs.format.bgr8, 60)
        config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 60)

        align_to = rs.stream.depth
        self.align = rs.align(align_to)

        self.pipeline.start(config)

    def fantome_callback(self, msg): 
        #Recherche de la position du fantome détecté par rapport au robot
        aligned_frames =  self.align.process(self.frames)
        if (msg.message.data == "fantome"):
            sound = Sound()
            sound.value=0
            self.sound_publisher.publish(sound)
        depth_frame = aligned_frames.get_depth_frame()
        aligned_color_frame = aligned_frames.get_color_frame()
        color_intrin = aligned_color_frame.profile.as_video_stream_profile().intrinsics
        depth = depth_frame.get_distance(int(msg.vect.x), int(msg.vect.y))
                    
        dx ,dy, dz = rs.rs2_deproject_pixel_to_point(color_intrin, [int(msg.vect.x),int(msg.vect.y)], depth)
        distance = math.sqrt(((dx)**2) + ((dy)**2) + ((dz)**2))
        goal = StringVect()
        goal.message.data=msg.message.data
        goal.vect.x=dx
        goal.vect.y=dy
        goal.vect.z=dz
        self.goal_publisher.publish(goal)

    def analyse_imgs(self):
        global color, rayon_detec
        self.frames = self.pipeline.wait_for_frames()
        color_frame = self.frames.first(rs.stream.color)
        color_image = np.asanyarray(color_frame.get_data())


        self.bridge=CvBridge()

        #Paramètres de traitement d'image
        lo=np.array([color-20, 100, 50])
        hi=np.array([color+20, 255,255])
        kernel = np.ones((7, 7), np.uint8)
        color_info=(0, 0, 255)

        image=cv2.cvtColor(color_image, cv2.COLOR_BGR2HSV)

        #Création du masque à appliquer à l'image
        mask=cv2.inRange(image, lo, hi)
        mask=cv2.erode(mask, kernel, iterations=1)
        mask=cv2.dilate(mask, kernel, iterations=1)
        image2=cv2.bitwise_and(color_image, color_image, mask= mask)

        #Publication des images en couleur dans un topic dédié
        msg_image = self.bridge.cv2_to_imgmsg(color_image,"bgr8")
        msg_image.header.stamp = self.get_clock().now().to_msg()
        msg_image.header.frame_id = "image"

        #Publication des images de distance dans un topic dédié
        depth_frame = self.frames.first(rs.stream.depth)
        depth_image = np.asanyarray(depth_frame.get_data())
        
        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)
        
        msg_depth = self.bridge.cv2_to_imgmsg(depth_colormap,"bgr8")
        msg_depth.header.stamp = msg_image.header.stamp
        msg_depth.header.frame_id = "depth"

        #Recherche de contours dans l'image à laquelle le masque a été appliqué
        elements=cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]
        if len(elements) > 0:
            c=max(elements, key=cv2.contourArea)
            ((x, y), rayon)=cv2.minEnclosingCircle(c)
            if rayon>rayon_detec:   #Condition de taille sur la détection d'éléments
                fantome=False
                if(int(x)-int(rayon)>0 and int(x)+int(rayon)<848 and int(y)-int(rayon)>0 and int(y)+int(rayon)<480):  

                    #Récupération d'un échantillon carré de l'image où se situe l'objet détecté
                    echantillon = color_image[int(y)-int(rayon):int(y)+int(rayon),int(x)-int(rayon):int(x)+int(rayon),]

                    msgMatching = ImageCoord()
                    msgMatching.image = self.bridge.cv2_to_imgmsg(echantillon,"bgr8")
                    msgMatching.depth = msg_depth
                    msgMatching.rayon = rayon
                    msgMatching.vect.x = x
                    msgMatching.vect.y = y
                    msgMatching.vect.z = 0.0

                    self.imagecoord_publisher.publish(msgMatching)

                    color_image=echantillon

        
        self.image_publisher.publish(msg_image)
        self.depth_publisher.publish(msg_depth)

process_img()