#!/usr/bin/env python3

from cv_bridge import CvBridge
import pyrealsense2 as rs
import signal, time, numpy as np
import sys, cv2, rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
import numpy as np
import matplotlib.pyplot as plt
from cv2 import calcHist


isOk= True
def signalInteruption(signum, frame):
    global isOk
    print( "\nCtrl-c pressed" )
    isOk= False

    return index
# Node processes:
def process_img(args=None):
    global isOk
    rclpy.init(args=args)
    rsNode= Realsense()
  
    
    while isOk:
        # rsNode.read_imgs()
        rsNode.analyse_imgs()
        rclpy.spin_once(rsNode, timeout_sec=0.1)


    # Stop streaming
    print("Ending...")
    rsNode.pipeline.stop()
    # Clean end
    rsNode.destroy_node()
    rclpy.shutdown()

# Realsense Node:
class Realsense(Node):
    def __init__(self, fps= 60):
        super().__init__('realsense')
        self.image_publisher = self.create_publisher(Image, '/sensor_image', 10)
        self.depth_publisher = self.create_publisher(Image, '/sensor_depth', 10)
        self.pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 848, 480, rs.format.bgr8, 60)
        config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 60)
        self.pipeline.start(config)

    def analyse_imgs(self):
        self.frames = self.pipeline.wait_for_frames()
        color_frame = self.frames.first(rs.stream.color)
        color_image = np.asanyarray(color_frame.get_data())

        self.bridge=CvBridge()

        b,g,r = cv2.split(color_image)
        #hist = calcHist(color_image, [1], None, [256], [0, 256])
        #plt.plot(hist, color='g') 
        #plt.title('Histogramme vert') 
        #plt.show()

        msg_image = self.bridge.cv2_to_imgmsg(color_image,"bgr8")
        msg_image.header.stamp = self.get_clock().now().to_msg()
        msg_image.header.frame_id = "image"
        self.image_publisher.publish(msg_image)

        depth_frame = self.frames.first(rs.stream.depth)
        depth_image = np.asanyarray(depth_frame.get_data())
        
        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)

        msg_depth = self.bridge.cv2_to_imgmsg(depth_colormap,"bgr8")
        msg_depth.header.stamp = msg_image.header.stamp
        msg_depth.header.frame_id = "depth"
        self.depth_publisher.publish(msg_depth)

process_img()